\documentclass[oneside]{projectpaper} %%Change `twoside' to `oneside' if you are printing only on the one side of each sheet.
\usepackage{amsmath}
\usepackage{amssymb,mathtools}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{algorithm}
\usepackage{algorithmic}
\graphicspath{}

\studname{Alex Wong}
\studmail{asw2181@columbia.edu}
\coursename{COMS E6232}
\uni{asw2181}

\begin{document}
\maketitle
\begin{abstract}
We look at the state of the art algorithm for the general case of the Asymmetric Traveling Salesman problem and its current known inapproximability bounds. The currently best algorithm, by Asadpour et al.\cite{AGM10}, details an $O$(log $n$ / log log $n$)-approximation algorithm for the general case of ATSP for costs satisfying the triangle inequality. An algorithm by Karpinski et al.\cite{KLS15} gives us a hardness of approximation bounds of 75 / 74 for ATSP. We also briefly touch on some constant factor approximation algorithms and recently new heuristics for special cases of ATSP, including an approach by Svensson et al.\cite{STV16} that details a constant factor approximation algorithm for a special case of ATSP that contains only two different edge weights of arbitrary weight where the costs satisfy the triangle inequality.
\end{abstract}
%%%%%%%%%%%%%%%%%%%%Section 1 Introduction%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}
The traveling salesman problem is one of the most well-known and studied problems in theoretical computer science and operations research. Many real world problems, from delivery routing to latency networks to DNA sequencing, can be framed as some variation of the traveling salesman problem. In this paper, we look at the current state of the art algorithms for the asymmetric traveling salesman problem (ATSP) where the costs satisfy the triangle inequality (costs from some point $u$ to point $w$ is at most the cost from point $u$ to point $v$ + cost from point $v$ to point $w$) but the cost from some point $u$ to point $v$ does not necessarily equal the cost from point $v$ to point $u$. From this description, we can frame the symmetric traveling salesman problem (the cost from some point $u$ to point $v$ does equal the cost from point $v$ to point $u$) as a special case of ATSP. \newline
\indent In Section 2, we provide an overview of an $O$(log $n$ / log log $n$)-approximation algorithm for the general case of ATSP for costs satisfying the triangle inequality which comes from the work of Asadpour et al. \cite{AGM10}. The $O$(log $n$ / log log $n$)-approximation algorithm introduces the concept of the "thinness" of a spanning tree where the thinness correlates with the approximation bound of ATSP. This is an improvement over the decades-long standing $\Theta$(log$n$)-approximation bound given by the work of Frieze et al. \cite{FGM83}. \newline
\indent In section 4 \newline
\indent Lastly, in section 5, we conclude with opinions on the hypothesized next steps towards a constant factor approximation algorithm for ATSP.

%%%%%%%%%%%%%%%%%%%%Section 2 An O logn / loglogn approx algo%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{An $O$(log $n$ / log log $n$)-approximation algorithm for ATSP}
Algorithm 1, on the next page, details the $O$(log $n$ / log log $n$)-approximation algorithm for ATSP (from \cite{AGM10} section 1). 
\begin{algorithm}
\caption{An $O$(log $n$ / log log $n$)-approximation algorithm for ATSP \cite{AGM10}}
\begin{algorithmic}
\STATE{\textbf{Input:} A set $V$ consisting of $n$ points and a cost function $c$ : $V \times V \rightarrow \mathbb{R}^+$ where the costs satisfy the triangle inequality.}
\STATE{\textbf{Output:} An $O$($\frac{logn}{log log n}$)-approximation to the ATSP instance described by the inputs $V$ and $c$.}
\STATE{}
\STATE{1. Solve the Held-Karp LP relaxation of the ATSP instance to get an optimum extreme point solution $\textbf{x}^*$. Create a symmetrized and scaled down version of $\textbf{x}^*$ from (5) and define it as $\textbf{z}^*$. $\textbf{z}^*$ is a vector which can be interpretted as a point in the relative interior (not touching any boundaries) of the spanning tree polytope $P$ created from an undirected graph supported by $\textbf{x}^*$ where we disregard the directions of arcs. Another way to think of $\textbf{z}^*$ is the marginal probabilities on the edges $z_{e}^{*}$ of an exponential  distribution on spanning trees $\tilde{p}(.)$.}
\STATE{}
\STATE{2. Let $E$ be the support graph of $\textbf{z}^*$ where we disregard the directions of arcs. We then find weights \{$\tilde{\gamma}\}_{e \in E}$ such that $\tilde{p}(T)$ is approximately proportional to $\text{exp}(\sum\limits_{e \in T}\tilde{\gamma}_e)$ where, for any edge $e \in E$, $\sum\limits_{T \in \mathcal{T} : T \ni e}\tilde{p}(T) \leq (1 + \epsilon)z_{e}^{*}$, for a small value $\epsilon$.}
\STATE{}
\STATE{3. Sample $\Theta$(log$n$) spanning trees $T_i$ from $\tilde{p}(.)$. Orient all the edges of the sampled spanning trees to minimize its cost since the spanning tree only has to be weakly connected. Let $\overrightarrow{T}$ represent an oriented tree. Let $T^{*}$ be the spanning tree that has minimum total cost amongst all the sample spanning trees.}
\STATE{}
\STATE{4. Find a minimum cost integral circulation that contains the oriented tree $\overrightarrow{T}^*$. This will give us a multigraph. Shortcut the multigraph to get a Eulerian tour and output the result.}
\end{algorithmic}
\end{algorithm}
Throughout the rest of this section, we will divide each step of the algorithm into subsection(s) to describe it in more detail and/or prove its correctness.

%Section 2.1 Preliminaries and Notation%
\subsection{Preliminaries and Notation}
In this subsection, we describe much of the notation that will be used throughout the rest of this section. We will also define the notion of "thinness" of a spanning tree. \newline
\indent Let $a = (u, v)$ be the arc (directed edge) from $u$ to $v$ and let $e = (u, v)$ be an undirected edge. Then, A (resp. E) is the set of arcs (resp. edges) in a directed (resp. undirected) graph G. \newline
\indent For a given function $f : A \rightarrow \mathbb{R}$, the cost of $f$ is defined as $c(f) := \sum\limits_{a \in A}c(a)f(a)$. For some set of arcs $S \subseteq A$, we define $f(S) := \sum\limits_{a \in S}f(a)$. The same notation is used for the edge set $E$ of an undirected graph. \newline
\indent For a subset of vertices $U \subseteq V$, we define
\begin{equation*}
  \delta^{+}(U) := \{a = (u, v) \in A : u \in U, v \notin U\},
\end{equation*}
\begin{equation*}
  \delta^{-}(U) := \{a = (u, v) \in A : u \notin U, v \in U\},
\end{equation*}
\begin{equation*}
  \delta(U) := \delta^{+}(U) \cup \delta^{-}(U),
\end{equation*}
\begin{equation*}
  A(U) := \{a = (u, v) \in A : u \in U, v \in U\}
\end{equation*}
to be the set of arcs that are leaving, entering, and contained in $U$, respectively. We also define $\delta^{+}(v) :=\delta^{+}(\{v\})$ and $\delta^{-}(v) :=\delta^{-}(\{v\})$ for each single vertex $v$. For an undirected graph, $\delta(U)$ represents the set of edges with just one endpoint in $U$ and $E(U)$ represents the edges that are contained within $U$. Lastly, all $log$ in equations represents the natural logarithm. \newline
\indent We say that a spanning tree $T$ is $\alpha$-thin with respect to $\textbf{z}$  if and only if: 
\begin{equation*}
|T \cap \delta(U)| \leq \alpha \cdot z(\delta(U)) \indent \forall U \subset V
\end{equation*}
which essentially states that for all the subsets of vertices $U$ of the spanning tree T, the number of edges in the cut between $U$ and $V \backslash U$ must be $\leq$ the thinness multiplied by the cost of the edges in the cut. \newline
\indent We also say that T is $(\delta, s)$-thin with respect to $\textbf{z}$ if and only if it is $\alpha$-thin and $c(T) \leq s \cdot OPT_{HK}$, which essentially states that the cost of $T$ is at most $s$ times the cost of the optimal Held-Karp solution.
\indent By showing that a spanning tree is "thin", we would be able to get a Eulerian augmentation of the spanning tree where the total cost is within a factor of $\alpha$ of the cost $OPT_{HK}$, which implies within the same factor of the optimum solution.

%Section 2.2 The Held-Karp Relaxation%
\subsection{The Held-Karp Relaxation}
We detail and prove step 1 of the algorithm. Given an ATSP instance with a cost function $c : V \times V \rightarrow \mathbb{R}^+$, we can get a lower bound on the optimal value of ATSP by the following linear programming (LP) relaxation defined on the complete bidirected graph over the vertex set $V$:
\begin{equation}
  min \sum\limits_{a}c(a)x_a
\end{equation}
\begin{equation}
  s.t. \ \ \textbf{x}(\delta^{+}(U)) \geq 1 \indent \forall U \subset V,
\end{equation}
\begin{equation}
  \textbf{x}(\delta^{+}(v)) = \textbf{x}(\delta^{-}(v)) = 1 \indent \forall v \in V,
\end{equation}
\begin{equation*}
  x_a \geq 0 \indent \forall a.
\end{equation*}
This relaxation is accurate since (2) makes sure that all the vertices are strongly connected and (3) makes sure that the indegree = outdegree for all vertices of $V$ which makes this a Eulerian graph. This relaxation is known as the Held-Karp relaxation \cite{HK70} and it's well-known that an optimal solution $\textbf{x}^*$ to the relaxation can be computed in polynomial time (using the ellipsoid method). Thus, we can say that $c(\textbf{x}^*) = OPT_{HK}$. Also, notice that (3) implies that any feasible solution \textbf{x} satisfies
\begin{equation}
  \textbf{x}(\delta^{+}(U)) =   \textbf{x}(\delta^{-}(U)) \indent \forall U \subset V.
\end{equation}

%Section 2.3 Proving z* \in Relative Interior of P%
\subsection{Proving z* $\in$ Relative Interior of P}
\indent As mentioned in the algorithm, $\textbf{z}^*$ is the symmetreized and scaled down version of $\textbf{x}^*$. So, we formally define
\begin{equation}
 \textbf{z}_{\{u, v\}}^{*} := \frac{n-1}{n}(\textbf{x}_{uv}^* + \textbf{x}_{vu}^*).
\end{equation}
\indent As mentioned in step 2 of the algorithm , we let $E$ be the support of $\textbf{z}^*$. We also let $A$ be the support of $\textbf{x}^*$ where $A = \{(u, v) : x_{uv}^{*} > 0 \}$. We also define the costs of all edges $e \in E$ where $c(e) = min \{c(a) : a \in \{(u, v), (v, u)\} \cap A \}, \ \forall e \in E$. This shows that $c(\textbf{z}*) < c(\textbf{x}*)$. Now we can prove the rest of step 1 of the algorithm and define a lemma:
\newline
\newline
\textbf{Lemma 2.1:} The vector $\textbf{z}^*$ belongs to the relative interior of the spanning tree polytope P.
\newline
\newline
\textbf{Proof:} From the characterization of the base polytope of a matroid given by Edmonds\cite{Edm71}, it follow that the spanning tree polytope P is defined by the following inequalities (see Corollary 50.7c of \cite{Sch03}):
\begin{equation}
P = \{z \in \mathbb{R}^E : z(E) = |V| - 1,
\end{equation}
\begin{equation}
z(E(U)) \leq |U| - 1 \indent \forall U \subset V \ where \ U \neq \emptyset,
\end{equation}
\begin{equation}
z_e \geq 0 \indent \forall e \in E.\}
\end{equation}
From this, we see that $\textbf{z}^*$ satisfies inequality (6) because:
\begin{equation*}
\forall v \in V, \textbf{x}^*(\delta^+(v)) = 1 \ \ \Rightarrow \ \ \textbf{x}^*(A) = n = |V| \ \ \Rightarrow \ \ \textbf{z}^*(E) = n - 1 = |V| - 1
\end{equation*}

%Section 2.4 Maximum Entropy Distribution%
\subsection{Maximum Entropy Distribution}
In the latter part of step 2 of the algorithm, to find the weights $\tilde{\gamma}_{e}, \forall e \in E$, requires lengthy non-trivial calculations which will not be detailed within this paper. There are two methods to find $\tilde{\gamma}_{e}$'s: either the combinatorial approach (see \cite{AGM10} section 7) where the basic idea is to iteratively tweak the weights of $\tilde{\gamma}_{e}$ until their marginals $= (1 + \epsilon/2)z_e$ or the ellipsoid method (see \cite{AGM10} section 8) where the basic idea is to find a near optimal solution of the dual of the convex program.

%%%%%%%%%%%%%%%%%%%%Section 3 An Inapproximability Bounds of ATSP%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Inapproximability Bounds of ATSP}

%%%%%%%%%%%%%%%%%%%%Section 4 Special Cases of ATSP%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Special Cases of ATSP}

\subsection{ATSP on Graphs with Bounded Genus}

\subsection{Polyloglog$n$ Integrality Gap of ATSP}

\subsection{Local-Connectivity ATSP}

%%%%%%%%%%%%%%%%%%%%Section 5 Conclusion%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Concluding Remarks}


\nocite{*}
\bibliographystyle{acm}
\bibliography{references}
\end{document}